{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(url):\n",
    "    operUrl = urllib.request.urlopen(url)\n",
    "    if(operUrl.getcode()==200):\n",
    "        data = operUrl.read()\n",
    "        jsonData = json.loads(data)\n",
    "    else:\n",
    "        print(\"Error receiving data\", operUrl.getcode())\n",
    "    return jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The structure of the label map will be:\n",
    "source : dest\n",
    "\n",
    "This way when utilizing the map, the target label will be able to use\n",
    "label = label_map.get(source) with None check for rejections\n",
    "'''\n",
    "label_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps For Creating Dictionary ##\n",
    "\n",
    "* Determine current mapping concept\n",
    "* Get a concept and all of its descendants\n",
    "* For exclusions, get all of its descendants\n",
    "* Delete from the current list of taxa\n",
    "* Repeat for all exclusion concepts\n",
    "* Repeat for all high level concepts of current mapping\n",
    "\n",
    "Reference https://docs.google.com/document/d/1CcZ4xmHUslIQjabQjeNOHj2ysXOhThjTZYBCbG885hw/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for current taxa\n",
    "current_high_level_label = \"Ray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_concept = 'Torpediniformes'\n",
    "# Call to get concept and its descendants\n",
    "json_data_taxa = getResponse('http://dsg.mbari.org/kb/v1/phylogeny/taxa/' + current_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get the list of terms to exclude from the current taxa search\n",
    "# Reference https://docs.google.com/document/d/1CcZ4xmHUslIQjabQjeNOHj2ysXOhThjTZYBCbG885hw/edit?usp=sharing\n",
    "current_exclusion_concept = 'Brisingida'\n",
    "current_exclusion = getResponse('http://dsg.mbari.org/kb/v1/phylogeny/taxa/' + current_exclusion_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the exclusion list to the items in the current search\n",
    "elements_to_prune = []\n",
    "for element in current_exclusion:\n",
    "    for i,entry in enumerate(json_data_taxa):\n",
    "        if element.get('name') == entry.get('name') and element.get('rank') == entry.get('rank'):\n",
    "            elements_to_prune.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the elements. It's important to do the list in reverse, because if you do it in ascending index order, your indices will be messed up.\n",
    "for idx in elements_to_prune[::-1]:\n",
    "    del(json_data_taxa[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping\n",
    "for element in json_data_taxa:\n",
    "    label_map[element.get('name')] = current_high_level_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete mistakes by mapping, only use if necessary\n",
    "keys = [key for key in label_map.keys()]\n",
    "for key in keys:\n",
    "    if label_map.get(key) == 'Barnacle':\n",
    "        print(key)\n",
    "        #del label_map[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the mapping to file\n",
    "out_path = ''\n",
    "with open(out_path, 'w') as fp:\n",
    "    json.dump(label_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it back to make sure it's ok\n",
    "with open(out_path, 'r') as fp:\n",
    "    test_file = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train and Val splits on the data downloaded from FathomNet ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First you need to download all the images and metadata in FathomNet that you want to use into a directory\n",
    "\n",
    "json_files = glob.glob('/mnt/md0/Projects/Fathomnet/Data_Files/2021-06-04-Download/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a train and val split\n",
    "\n",
    "train_file = open('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/train_v2.csv','w')\n",
    "train_csv = csv.writer(train_file,delimiter=',')\n",
    "val_file = open('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/val_v2.csv','w')\n",
    "val_csv = csv.writer(val_file,delimiter=',')\n",
    "\n",
    "'''\n",
    "Loop over media, and gather annotations. Randomly assign media to train or val\n",
    "'''\n",
    "for i,ann_file in enumerate(json_files):\n",
    "    if i % 100 == 0:\n",
    "        print(f'File {i} of {len(json_files)}')\n",
    "    media_file = ann_file.split('.json')[0] + '.png'\n",
    "    with open(ann_file,'r') as fp:\n",
    "        anns = json.load(fp)\n",
    "        \n",
    "    rows = []\n",
    "    for ann in anns.get('boundingBoxes'):\n",
    "        try:\n",
    "            row = [\n",
    "                    media_file, \n",
    "                    int(ann.get('x')),\n",
    "                    int(ann.get('y')),\n",
    "                    int((ann.get('x') + ann.get('width'))),\n",
    "                    int((ann.get('y') + ann.get('height'))),\n",
    "                    label_map.get(ann.get('concept'))]\n",
    "        except:\n",
    "            print(\"Bad Row\")\n",
    "            print(ann)\n",
    "            continue\n",
    "\n",
    "        if row[1] == row[3] or row[2] == row[4]:\n",
    "            print('bad dimensions')\n",
    "            print(ann)\n",
    "            continue\n",
    "        if row[1] > row[3] or row[2] > row[4]:\n",
    "            print('bad dimensions')\n",
    "            print(ann)\n",
    "            continue\n",
    "            \n",
    "        if label_map.get(ann.get('concept')) is not None:\n",
    "            rows.append(row)\n",
    "            \n",
    "    if np.random.random() < 0.85:\n",
    "        [train_csv.writerow(row) for row in rows]\n",
    "    else:\n",
    "        [val_csv.writerow(row) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "        \"Anemone\" : 0,\n",
    "        \"Fish\" : 1,\n",
    "        \"Eel\" : 2,\n",
    "        \"Gastropod\" : 3,\n",
    "        \"Sea star\" : 4,\n",
    "        \"Feather star\" : 5,\n",
    "        \"Sea cucumber\" : 6,\n",
    "        \"Urchin\" : 7,\n",
    "        \"Glass sponge\" : 8,\n",
    "        \"Sea fan\" :9,\n",
    "        \"Soft coral\" : 10,\n",
    "        \"Sea pen\" : 11,\n",
    "        \"Stony coral\" : 12,\n",
    "        \"Ray\" : 13,\n",
    "        \"Crab\" : 14,\n",
    "        \"Shrimp\" : 15,\n",
    "        \"Squat lobster\" : 16,\n",
    "        \"Flatfish\" : 17,\n",
    "        \"Sea spider\" : 18,\n",
    "        \"Worm\" : 19\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = [key for key in category_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_df = pd.read_csv('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/train_file_v2.csv',names=['filename', 'x1','y1','x2','y2','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Urchin           25568\n",
       "Fish             23199\n",
       "Sea cucumber     21470\n",
       "Anemone          17173\n",
       "Sea star         13767\n",
       "Sea fan          12077\n",
       "Sea pen           9198\n",
       "Glass sponge      7940\n",
       "Crab              7001\n",
       "Shrimp            4954\n",
       "Worm              4503\n",
       "Gastropod         3853\n",
       "Flatfish          3846\n",
       "Soft coral        3612\n",
       "Ray               2930\n",
       "Feather star      2899\n",
       "Squat lobster     2641\n",
       "Eel               2371\n",
       "Stony coral        318\n",
       "Sea spider         210\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file_df = pd.read_csv('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/val_file_v2.csv',names=['filename', 'x1','y1','x2','y2','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Urchin           4173\n",
       "Sea cucumber     3754\n",
       "Fish             3742\n",
       "Anemone          2924\n",
       "Sea star         2317\n",
       "Sea fan          2097\n",
       "Sea pen          1652\n",
       "Glass sponge     1443\n",
       "Crab             1200\n",
       "Gastropod         800\n",
       "Shrimp            772\n",
       "Worm              752\n",
       "Flatfish          608\n",
       "Soft coral        555\n",
       "Squat lobster     530\n",
       "Ray               476\n",
       "Feather star      405\n",
       "Eel               358\n",
       "Stony coral        48\n",
       "Sea spider         41\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_file_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_df['url'] = ''\n",
    "train_file_df['id'] = ''\n",
    "train_file_df['uuid'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train_file_df)):\n",
    "    with open(train_file_df.iat[idx,0].split('.png')[0] + '.json','r') as json_file:\n",
    "        a = json.load(json_file)\n",
    "    train_file_df.iat[idx,6] = a.get('url')\n",
    "    train_file_df.iat[idx,7] = a.get('id')\n",
    "    train_file_df.iat[idx,8] = a.get('uuid')\n",
    "    train_file_df.iat[idx,0] = train_file_df.iat[idx,0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forget what this is for, but probably fixing some sort of file naming issue\n",
    "train_file_df.iat[0,0] = '/mnt/md0/Projects/Fathomnet/Data_Files/2021-06-04-Download/Beringraja-rhina03_13_12_16.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write new train file with url, id, and uuid fields, for later use and provenance\n",
    "train_file_df.to_csv('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/val_file_v3_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq = train_file_df['uuid'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_val = val_file_df['uuid'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_val_uuids = [key for key in uniq_val.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_uuids = [key for key in uniq.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in unique_val_uuids:\n",
    "    if key in unique_train_uuids:\n",
    "        continue\n",
    "    else:\n",
    "        unique_train_uuids.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d320585b-d8db-4e78-a8d4-9fb05655bcf4    98\n",
       "065f33b7-84ed-456f-b76f-d913707dc517    91\n",
       "35ce1c47-d045-48fd-b122-4566429a36f0    89\n",
       "8868298a-5a85-40d6-a36f-a8ff91661a03    86\n",
       "46ffba91-4ce9-451b-a707-f0f19ea92f3e    83\n",
       "                                        ..\n",
       "12181d1f-7de1-446e-82b4-8a36b7109ee9     1\n",
       "6b1a73d1-af78-4601-aad3-4268667ab802     1\n",
       "19b66c91-4f4e-481f-b967-13ea9839f35f     1\n",
       "d15607f3-ed4d-4cf8-8faa-ba54c3e149fd     1\n",
       "245ff1b3-be7b-46a3-b4bf-83a6ed192fec     1\n",
       "Name: uuid, Length: 27882, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_df['uuid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = []\n",
    "for uuid in unique_train_uuids:\n",
    "    try:\n",
    "        fnames.append(train_file_df[train_file_df['uuid'] == uuid].iat[0,0])\n",
    "    except:\n",
    "        fnames.append(val_file_df[val_file_df['uuid'] == uuid].iat[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/benthic_label_map.json','r') as json_file:\n",
    "    label_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file_df = pd.read_csv('/mnt/md0/Projects/Fathomnet/Training_Files/2021-06-29-Detectron/val_file_v2_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternatipathes\n"
     ]
    }
   ],
   "source": [
    "# This is where we look for things to remove or rename based on low population of labels\n",
    "for key in label_map.keys():\n",
    "    if label_map.get(key) == 'Black coral':\n",
    "        print(key)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch-1.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5b684c4beac959e5d1c3e8c100108bb7fea54bd868133133bee67709bde0ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
